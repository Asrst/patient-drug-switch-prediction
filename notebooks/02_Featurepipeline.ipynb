{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/drug-switch-preprocessing/__results__.html\n",
      "/kaggle/input/drug-switch-preprocessing/custom.css\n",
      "/kaggle/input/drug-switch-preprocessing/train.parquet\n",
      "/kaggle/input/drug-switch-preprocessing/__notebook__.ipynb\n",
      "/kaggle/input/drug-switch-preprocessing/train_labels.parquet\n",
      "/kaggle/input/drug-switch-preprocessing/test.parquet\n",
      "/kaggle/input/drug-switch-preprocessing/__output__.json\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/_DS_Store\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/fitness_values_2.csv\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/train_data.csv\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/test_data.csv\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/train_labels.csv\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/Sample Submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import sparse \n",
    "import scipy as sp\n",
    "import time\n",
    "from scipy.sparse import hstack\n",
    "import time\n",
    "import os\n",
    "data_paths = {}\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        data_paths[filename] = os.path.join(dirname, filename)\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparse_matrix(data):\n",
    "    return sparse.csr_matrix(data)\n",
    "\n",
    "def sparse_vars(a, axis=None):\n",
    "    \"\"\" \n",
    "    Variance of sparse matrix a\n",
    "    var = mean(a**2) - mean(a)**2\n",
    "    \"\"\"\n",
    "    a_squared = a.copy()\n",
    "    a_squared.data **= 2\n",
    "    return a_squared.mean(axis) - np.square(a.mean(axis))\n",
    "\n",
    "def sparse_stds(a, axis=None):\n",
    "    \"\"\"\n",
    "    Standard deviation of sparse matrix a\n",
    "    std = sqrt(var(a))\n",
    "    \"\"\"\n",
    "    return np.sqrt(sparse_vars(a, axis))\n",
    "\n",
    "# to get feature stats\n",
    "def create_fitness_stats(df, cols, pos_idx, neg_idx, nans = True):\n",
    "    \n",
    "    stat_df = pd.DataFrame(data = cols, columns=['feature_name'])\n",
    "    \n",
    "    if nans:\n",
    "        ###\n",
    "        stat_df['avg_0'] = np.nanmean(df[neg_idx,:].astype(float), axis = 0)\n",
    "        stat_df['avg_1'] = np.nanmean(df[pos_idx,:].astype(float), axis = 0)\n",
    "        ###\n",
    "        stat_df['sd_0'] = np.nanstd(df[neg_idx,:].astype(float), axis = 0)\n",
    "        stat_df['sd_1'] = np.nanstd(df[pos_idx,:].astype(float), axis = 0)\n",
    "        \n",
    "    if not nans:\n",
    "        ###\n",
    "        stat_df['avg_0'] = np.ravel(df[neg_idx,:].mean(axis = 0))\n",
    "        stat_df['avg_1'] = np.ravel(df[pos_idx,:].mean(axis = 0))\n",
    "        ###\n",
    "        stat_df['sd_0'] = np.ravel(sparse_stds(df[neg_idx,:], axis = 0))\n",
    "        stat_df['sd_1'] = np.ravel(sparse_stds(df[pos_idx,:], axis = 0))\n",
    "        \n",
    "    return stat_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### recency feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_recency_feature(df):\n",
    "    start = time.time()\n",
    "    cdfs = []\n",
    "    for col in ['event_name', 'specialty', 'plan_type']:\n",
    "        cat_df = df.groupby([\"id\", col]).agg({\"event_time\":np.min}).unstack(level=col)\n",
    "        cat_df.columns = ['__'.join(['recency', col, name,]) for name in cat_df.columns.droplevel()]\n",
    "        cdfs.append(cat_df)\n",
    "    res_df = pd.concat(cdfs, axis = 1)\n",
    "    # res_df = res_df.fillna('##')\n",
    "    end = time.time()\n",
    "    print('time taken (in secs) for recency features creation:', end-start)\n",
    "    \n",
    "    res_idx, res_col = np.array(res_df.index), np.array(res_df.columns)\n",
    "    res_data = res_df.values\n",
    "\n",
    "    del res_df\n",
    "    return res_idx, res_col, res_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### frequency feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_frequency_feature(temp_df):\n",
    "    \"\"\"\n",
    "    function to create frequency feature \n",
    "    \"\"\"\n",
    "    start = time.time()\n",
    "    cat_dfs = []\n",
    "    for num in np.arange(1080,0,-30):\n",
    "        temp_df.loc[temp_df['event_time'] > int(num), 'event_time'] = np.nan\n",
    "        for col in ['event_name', 'specialty', 'plan_type']:\n",
    "            cat_df = temp_df.groupby([\"id\", col],).agg({\"event_time\": 'count'}).unstack(level=col)\n",
    "            cat_df.columns = ['__'.join(['frequency', col, name, str(int(num))]) for name in cat_df.columns.droplevel()]\n",
    "            cat_dfs.append(cat_df)\n",
    "    res_df = pd.concat(cat_dfs, axis = 1)\n",
    "    res_df = res_df.fillna(0)\n",
    "    end = time.time()\n",
    "    print('time taken (in secs) for frequency feature creation:', end-start)\n",
    "    \n",
    "    res_idx, res_col = np.array(res_df.index), np.array(res_df.columns)\n",
    "    res_data = get_sparse_matrix(res_df.values)\n",
    "    \n",
    "    del res_df\n",
    "    # get data\n",
    "    return res_idx, res_col, res_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NormChange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_df(temp_post_df):\n",
    "    \"\"\"\n",
    "    function to create feature matrix greather than time period for comparison\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    cat_dfs = []\n",
    "    for num in np.arange(1080/2,0,-30):\n",
    "        # making > null i.e keeping <=\n",
    "        temp_post_df.loc[temp_post_df['event_time'] > int(num), 'event_time'] = np.nan\n",
    "        for col in ['event_name', 'specialty', 'plan_type']:\n",
    "            cat_df = temp_post_df.groupby([\"id\", col]).agg({\"event_time\": 'count'}).unstack(level=col)\n",
    "            cat_df = cat_df/num\n",
    "            cat_df.columns = ['__'.join(['normChange', col, name, str(int(num))]) for name in cat_df.columns.droplevel()]\n",
    "            cat_dfs.append(cat_df)  \n",
    "    post_df = pd.concat(cat_dfs, axis = 1)\n",
    "    return post_df.fillna(0)\n",
    "\n",
    "\n",
    "def get_pre_df(temp_pre_df):\n",
    "    \"\"\"\n",
    "    function to create feature matrix less than time period for comparison\n",
    "    \"\"\"\n",
    "    \n",
    "    event_time_max = temp_pre_df['event_time'].max()\n",
    "    cat_dfs = []\n",
    "    for num in np.arange(0,(1080/2)+1,30)[1:]:\n",
    "        # making <= null i.e keeping >\n",
    "        temp_pre_df.loc[temp_pre_df['event_time'] <= int(num), 'event_time'] = np.nan\n",
    "        for col in ['event_name', 'specialty', 'plan_type']:\n",
    "            cat_df = temp_pre_df.groupby([\"id\", col]).agg({\"event_time\": 'count'}).unstack(level=col)\n",
    "            cat_df = cat_df/(event_time_max-num)\n",
    "            cat_df.columns = ['__'.join(['normChange', col, name, str(int(num))]) for name in cat_df.columns.droplevel()]\n",
    "            cat_dfs.append(cat_df)\n",
    "    pre_df = pd.concat(cat_dfs, axis = 1)        \n",
    "    return pre_df.fillna(0)\n",
    "\n",
    "\n",
    "def create_norm_feature(temp_df):\n",
    "    \"\"\"\n",
    "    function to create norm change feature\n",
    "    \"\"\"\n",
    "    \n",
    "    start = time.time()\n",
    "    \n",
    "    post_df = get_post_df(temp_df)\n",
    "    pre_df = get_pre_df(temp_df)\n",
    "    \n",
    "    res_col = np.array(pre_df.columns)\n",
    "    post_df = post_df[res_col]\n",
    "    r = np.where(post_df > pre_df, 1, 0)\n",
    "    \n",
    "    res_idx = np.array(post_df.index)\n",
    "    res_data = get_sparse_matrix(r)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('time taken (in secs) for norm change feature creation:', end-start)\n",
    "    \n",
    "    # df1.where(df1.values==df2.values)\n",
    "    # post_df.where(post_df > pre_df, 1, 0, inplace = True)\n",
    "    del post_df, pre_df\n",
    "    return res_idx, res_col, res_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transform & save train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data_df, target_df = None):\n",
    "    \"\"\"\n",
    "    function to transform given matrix into feature matrix\n",
    "    \"\"\"\n",
    "    rec_idx, rec_col, rec_data = create_recency_feature(data_df)\n",
    "    freq_idx, freq_col, freq_data = create_frequency_feature(data_df)\n",
    "    norm_idx, norm_col, norm_data = create_norm_feature(data_df)\n",
    "\n",
    "    # with hstack function we are concatinating a sparse matrix and a dense matirx :)\n",
    "    feat_df = hstack((rec_data, freq_data, norm_data))\n",
    "    print('Final feature matrix shape:', feat_df.shape)\n",
    "    \n",
    "    # merge all the feature names\n",
    "    feat_names = list(rec_col) + list(freq_col) + list(norm_col)\n",
    "    \n",
    "    if isinstance(target_df, pd.core.frame.DataFrame):\n",
    "        # get +ve & -ve indices\n",
    "        one_idx = target_df[target_df['outcome_flag'] == 1]['id'].index.tolist()\n",
    "        zero_idx = target_df[target_df['outcome_flag'] == 0]['id'].index.tolist()\n",
    "        \n",
    "        # calculate fitness values of features\n",
    "        rcdf = create_fitness_stats(rec_data, rec_col, one_idx, zero_idx, nans = True)\n",
    "        fqdf = create_fitness_stats(freq_data, freq_col, one_idx, zero_idx, nans = False)\n",
    "        nrdf = create_fitness_stats(norm_data, norm_col, one_idx, zero_idx, nans=False)\n",
    "        fit_df = rcdf.append(fqdf).append(nrdf)\n",
    "        fit_df.reset_index(drop=1)\n",
    "        return feat_df, feat_names, fit_df\n",
    "    \n",
    "    return feat_df, feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, path):\n",
    "    return sparse.save_npz(path, data)\n",
    "\n",
    "def load_data(path):\n",
    "    return sparse.load_npz(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: (14446880, 7) Index(['patient_id', 'event_name', 'event_time', 'specialty', 'plan_type',\n",
      "       'patient_payment', 'id'],\n",
      "      dtype='object')\n",
      "train labels (16683, 3) Index(['patient_id', 'outcome_flag', 'id'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_parquet(data_paths['train.parquet'])\n",
    "print('train data:', train_df.shape, train_df.columns)\n",
    "\n",
    "target_df = pd.read_parquet(data_paths['train_labels.parquet'])\n",
    "print('train labels', target_df.shape, target_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken (in secs) for recency features creation: 7.36030387878418\n",
      "time taken (in secs) for frequency feature creation: 267.0937509536743\n",
      "time taken (in secs) for norm change feature creation: 249.55682754516602\n",
      "Final feature matrix shape: (16683, 41525)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:27: RuntimeWarning: Mean of empty slice\n",
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:28: RuntimeWarning: Mean of empty slice\n",
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/nanfunctions.py:1666: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  keepdims=keepdims)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((16683, 41525), 41525)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feat, train_feat_names, train_fit_df = transform_data(train_df, target_df)\n",
    "train_feat.shape, len(train_feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(train_feat, 'train_features.npz')\n",
    "del train_df, target_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6256130, 7) Index(['patient_id', 'event_name', 'event_time', 'specialty', 'plan_type',\n",
      "       'patient_payment', 'id'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_parquet(data_paths['test.parquet'])\n",
    "print(test_df.shape, test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken (in secs) for recency features creation: 2.2142653465270996\n",
      "time taken (in secs) for frequency feature creation: 104.43709707260132\n",
      "time taken (in secs) for norm change feature creation: 114.7191002368927\n",
      "Final feature matrix shape: (7148, 41525)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((7148, 41525), 41525)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat, test_feat_names = transform_data(test_df)\n",
    "test_feat.shape, len(test_feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(test_feat, 'test_features.npz')\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(train_feat_names == test_feat_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(train_feat_names, columns = ['feature']).to_csv('train_feature_names.csv', index = False)\n",
    "pd.DataFrame(test_feat_names, columns = ['feature']).to_csv('test_feature_names.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fitness calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_calculation(data):\n",
    "    if ((data['sd_0'] == 0 ) and (data['sd_1'] == 0)) and (((data['avg_0'] == 0) and (data['avg_1'] != 0)) or ((data['avg_0'] != 0) and (data['avg_1'] == 0))):\n",
    "        return 9999999999\n",
    "    elif (((data['sd_0'] == 0 ) and (data['sd_1'] != 0)) or ((data['sd_0'] != 0) and (data['sd_1'] == 0))) and (data['avg_0'] == data['avg_1']):\n",
    "        return 1\n",
    "    elif ((data['sd_0'] != 0 ) and (data['sd_1'] != 0)) and (data['avg_0'] != 0):\n",
    "        return ((data['avg_1']/data['sd_1'])/(data['avg_0']/data['sd_0']))\n",
    "    elif ((data['sd_0'] != 0 ) and (data['sd_1'] != 0)) and ((data['avg_0'] == 0) and (data['avg_1'] != 0)):\n",
    "        return 9999999999\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_fitness_val \n",
    "train_fit_df['fitness_value'] = train_fit_df.apply(fitness_calculation, axis = 1)\n",
    "train_fit_df.to_csv('train_fitness_values.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
