{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/_DS_Store\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/fitness_values_2.csv\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/train_data.csv\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/test_data.csv\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/train_labels.csv\n",
      "/kaggle/input/drug-switch-classification/DS_ML_Recruitment_V2.0/Sample Submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from scipy import sparse \n",
    "import scipy as sp\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "data_paths = {}\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        data_paths[filename] = os.path.join(dirname, filename)\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "def create_num_id(df):\n",
    "    \"\"\"\n",
    "    create an unique numerical index for patients\n",
    "    \"\"\"\n",
    "    df['id'] = df['patient_id'].apply(lambda x:int(x.split('_')[1]))\n",
    "    return df\n",
    "\n",
    "def sort_data(df, col_order=[\"id\", 'event_name', 'specialty', 'plan_type']):\n",
    "    \"\"\"\n",
    "    to sort the data in the predefined order\n",
    "    \"\"\"\n",
    "    df.sort_values(col_order, inplace = True)\n",
    "    df.reset_index(drop=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16683, 2) Index(['patient_id', 'outcome_flag'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "target_df = pd.read_csv(data_paths['train_labels.csv'])\n",
    "print(target_df.shape, target_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get +ve & -ve indices\n",
    "# one_idx = target_df[target_df['outcome_flag'] == 1]['id'].index.tolist()\n",
    "# zero_idx = target_df[target_df['outcome_flag'] == 0]['id'].index.tolist()\n",
    "\n",
    "target_df = create_num_id(target_df)\n",
    "target_df = sort_data(target_df, col_order=['id'])\n",
    "target_df.to_parquet('train_labels.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14446880, 6) Index(['patient_id', 'event_name', 'event_time', 'specialty', 'plan_type',\n",
      "       'patient_payment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(data_paths['train_data.csv'])\n",
    "print(train_df.shape, train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = create_num_id(train_df)\n",
    "train_df = sort_data(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6256395, 6) Index(['patient_id', 'event_name', 'event_time', 'specialty', 'plan_type',\n",
      "       'patient_payment'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv(data_paths['test_data.csv'])\n",
    "print(test_df.shape, test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = create_num_id(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing types in train event_name 0\n",
      "missing types in train specialty 13\n",
      "missing types in train plan_type 0\n",
      "missing types in test event_name 0\n",
      "missing types in test specialty 36\n",
      "missing types in test plan_type 0\n"
     ]
    }
   ],
   "source": [
    "cat_columns = ['event_name', 'specialty', 'plan_type']\n",
    "train_unique_col_values = {col:train_df[col].unique() for col in cat_columns}\n",
    "test_unique_col_values = {col:test_df[col].unique() for col in cat_columns}\n",
    "\n",
    "# train missed\n",
    "train_missed = {k:[] for k in cat_columns}\n",
    "for col in cat_columns:\n",
    "    for col_type in test_unique_col_values[col]:\n",
    "        if col_type not in train_unique_col_values[col]:\n",
    "            train_missed[col].append(col_type)\n",
    "    print('missing types in train', col, len(train_missed[col]))\n",
    "\n",
    "# missed values\n",
    "test_missed = {k:[] for k in cat_columns}\n",
    "for col in cat_columns:\n",
    "    for col_type in train_unique_col_values[col]:\n",
    "        if col_type not in test_unique_col_values[col]:\n",
    "            test_missed[col].append(col_type)\n",
    "    print('missing types in test', col, len(test_missed[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all patient test ids\n",
    "test_patient_ids = test_df['patient_id'].values\n",
    "\n",
    "# create duplicate values for missing data\n",
    "dup_values = []\n",
    "for col in cat_columns:\n",
    "    iter_items = test_missed[col]\n",
    "    if len(iter_items) > 0:\n",
    "        for item in iter_items:\n",
    "            rc = random.choice(test_patient_ids)\n",
    "            et = np.nan\n",
    "            pa = np.nan\n",
    "            if col == 'event_name':\n",
    "                en = item\n",
    "                sn = random.choice(train_unique_col_values['specialty'])\n",
    "                pt = random.choice(train_unique_col_values['plan_type'])\n",
    "            if col == 'specialty':\n",
    "                en = random.choice(train_unique_col_values['event_name'])\n",
    "                sn = item\n",
    "                pt = random.choice(train_unique_col_values['plan_type'])     \n",
    "            if col == 'plan_type':\n",
    "                en = random.choice(train_unique_col_values['event_name'])\n",
    "                sn = random.choice(train_unique_col_values['specialty'])\n",
    "                pt = item\n",
    "            dup_values.append([rc, en, et, sn, pt, pa, int(rc.split('_')[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = test_df[~(test_df['specialty'].isin(train_missed['specialty']))].reset_index(drop = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36, 7),\n",
       " Index(['patient_id', 'event_name', 'event_time', 'specialty', 'plan_type',\n",
       "        'patient_payment', 'id'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_df = pd.DataFrame(data = dup_values, columns = test_df.columns)\n",
    "dup_df.shape, dup_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6256130, 7),\n",
       " Index(['patient_id', 'event_name', 'event_time', 'specialty', 'plan_type',\n",
       "        'patient_payment', 'id'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = test_df.append(dup_df)\n",
    "test_df = sort_data(test_df)\n",
    "test_df.shape, test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_parquet('train.parquet', index = False)\n",
    "test_df.to_parquet('test.parquet', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
